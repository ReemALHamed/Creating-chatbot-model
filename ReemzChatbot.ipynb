{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReemzChatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReemALHamed/Creating-chatbot-model/blob/main/ReemzChatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlklOQpjEODS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162c7b3d-9c67-427c-cb90-14041dea3f45"
      },
      "source": [
        "pip install tflearn "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 107 kB 23.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=f6ebe03b5c83277b657693f0da0dac5f88ac57474ee640a5e0701a24b529eaf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAEG0UiP0J2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279d0cad-5d59-43d5-8c47-a627b59c4a94"
      },
      "source": [
        "#libraries needed for NLP\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VFBm7pmUKm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f581cb-ffc8-4471-d941-a1686579c87c"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer=LancasterStemmer()\n",
        "\n",
        "#Libararies needed for TensorFlow processing\n",
        "from tensorflow.python.framework import ops\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tflearn\n",
        "import random\n",
        "import json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5smYz21oURVZ",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "fee032a5-6085-47d3-a87f-2cc2518ece09"
      },
      "source": [
        "# import the Json file containing the chat-bot intents\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3f8cd468-e966-472f-995a-db900d6636eb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3f8cd468-e966-472f-995a-db900d6636eb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving intents.json to intents.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents.json': b'{\"intents\": [\\r\\n        {\"tag\": \"greeting\",\\r\\n         \"patterns\": [\"Hi\", \"How are you\", \"Is anyone there?\", \"Hello\", \"Good day\", \"Whats up\" , \"Good morning\" , \"Good evening\" , \"hello\" , \"hey\" , \"what\\'s up\"],\\r\\n         \"responses\": [\"Hello!\", \"Good to see you!\", \"Hi there, how can I help?\"],\\r\\n         \"context_set\": \"\"\\r\\n        },\\r\\n        {\"tag\": \"goodbye\",\\r\\n         \"patterns\": [\"cya\", \"See you later\", \"Goodbye\", \"I am Leaving\", \"Have a Good day\",\"bye\",\"i have to go\",\"gotta go\"],\\r\\n         \"responses\": [\"Sad to see you go :(\", \"Talk to you later\", \"Goodbye!\"],\\r\\n         \"context_set\": \"\"\\r\\n        },\\r\\n        {\"tag\": \"age\",\\r\\n         \"patterns\": [\"how old\", \"how old are you\", \"what is your age\", \"how old are you\", \"age?\"],\\r\\n         \"responses\": [\"I am old and wise\", \"trying to stay fit and young!\"],\\r\\n         \"context_set\": \"\"\\r\\n        },\\r\\n        {\"tag\": \"name\",\\r\\n         \"patterns\": [\"what is your name\", \"what should I call you\", \"whats your name?\", \"who are you?\"],\\r\\n          \"responses\": [ \"You can call me Reemz.\", \"I\\'m Reemz!\", \"I\\'m Reemz.\" ],\\r\\n         \"context_set\": \"\"\\r\\n        },\\r\\n        {\"tag\": \"help\",\\r\\n         \"patterns\": [\"Id like to ask something\", \"what can you do\", \"can you help me?\", \"can i tell you something\"],\\r\\n         \"responses\": [\"I\\'m here to help you!\", \"I can help you with whatever you tell me to.\"],\\r\\n         \"context_set\": \"\"\\r\\n        }\\r\\n   ]\\r\\n}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dTI67NhUYn9"
      },
      "source": [
        "#import chat-bot intents file\n",
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-GwRycQXpnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce54822-e86e-423f-8679-f24520044dad"
      },
      "source": [
        "# print the i=Json file content\n",
        "intents"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'context_set': '',\n",
              "   'patterns': ['Hi',\n",
              "    'How are you',\n",
              "    'Is anyone there?',\n",
              "    'Hello',\n",
              "    'Good day',\n",
              "    'Whats up',\n",
              "    'Good morning',\n",
              "    'Good evening',\n",
              "    'hello',\n",
              "    'hey',\n",
              "    \"what's up\"],\n",
              "   'responses': ['Hello!', 'Good to see you!', 'Hi there, how can I help?'],\n",
              "   'tag': 'greeting'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['cya',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'I am Leaving',\n",
              "    'Have a Good day',\n",
              "    'bye',\n",
              "    'i have to go',\n",
              "    'gotta go'],\n",
              "   'responses': ['Sad to see you go :(', 'Talk to you later', 'Goodbye!'],\n",
              "   'tag': 'goodbye'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['how old',\n",
              "    'how old are you',\n",
              "    'what is your age',\n",
              "    'how old are you',\n",
              "    'age?'],\n",
              "   'responses': ['I am old and wise', 'trying to stay fit and young!'],\n",
              "   'tag': 'age'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['what is your name',\n",
              "    'what should I call you',\n",
              "    'whats your name?',\n",
              "    'who are you?'],\n",
              "   'responses': ['You can call me Reemz.', \"I'm Reemz!\", \"I'm Reemz.\"],\n",
              "   'tag': 'name'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['Id like to ask something',\n",
              "    'what can you do',\n",
              "    'can you help me?',\n",
              "    'can i tell you something'],\n",
              "   'responses': [\"I'm here to help you!\",\n",
              "    'I can help you with whatever you tell me to.'],\n",
              "   'tag': 'help'}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-kbxeyoiwET"
      },
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore = ['?']\n",
        "\n",
        "#loop through each sentence in the intent's patterns\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        #tokenize each and every word in the sentence\n",
        "        w=nltk.word_tokenize(pattern)\n",
        "        \n",
        "        #add word to the word list\n",
        "        words.extend(w)\n",
        "        \n",
        "        #add word(s) to documents\n",
        "        documents.append((w, intent['tag']))\n",
        "        \n",
        "        #add tags to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_ityTwjlxx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530c744e-2f34-46c3-883f-1ac4d89fb2da"
      },
      "source": [
        "#perform stemming and lower each word as well as remove duplicates\n",
        "\n",
        "words=[stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
        "words=sorted(list(set(words)))\n",
        "\n",
        "#remove duplicate classes\n",
        "classes=sorted(list(set(classes)))\n",
        "\n",
        "print (len(documents), \"documents\")\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(words), \"unique stemmed words\", words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32 documents\n",
            "5 classes ['age', 'goodbye', 'greeting', 'help', 'name']\n",
            "46 unique stemmed words [\"'s\", 'a', 'ag', 'am', 'anyon', 'ar', 'ask', 'bye', 'cal', 'can', 'cya', 'day', 'do', 'ev', 'go', 'good', 'goodby', 'got', 'hav', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'id', 'is', 'lat', 'leav', 'lik', 'me', 'morn', 'nam', 'old', 'see', 'should', 'someth', 'ta', 'tel', 'ther', 'to', 'up', 'what', 'who', 'yo', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1388GULyl5oS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e06c80-93d1-42b1-ba02-0e4615dfa3c8"
      },
      "source": [
        "#create training data\n",
        "training=[]\n",
        "output=[]\n",
        "\n",
        "#create an empty array for output\n",
        "output_empty=[0]*len(classes)\n",
        "\n",
        "#create training set bag of words for each sentence\n",
        "for doc in documents:\n",
        "  #initialize bag of words\n",
        "  bag=[]\n",
        "  #list of tokenized words for the pattern\n",
        "  pattern_words=doc[0]\n",
        "  #stemming each word\n",
        "  pattern_words=[stemmer.stem(word.lower()) for word in pattern_words]\n",
        "  #create bag of words array\n",
        "  for w in words:\n",
        "    bag.append(1) if w in pattern_words else bag.append(0)\n",
        "    \n",
        "  #output is 1 for current tag and o for the rest of other tags\n",
        "  output_row=list(output_empty)\n",
        "  output_row[classes.index(doc[1])]=1\n",
        "    \n",
        "  training.append([bag,output_row])\n",
        "    \n",
        "#shuffling features and turning it into np.array\n",
        "random.shuffle(training)\n",
        "training=np.array(training)\n",
        "  \n",
        "#creating training lists\n",
        "train_x =list(training[:,0])\n",
        "train_y =list(training[:,1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2TNEBYFpPBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c78d558-9060-43ac-93bd-8839820f2b88"
      },
      "source": [
        "#resetting underlying graph data\n",
        "ops.reset_default_graph()\n",
        "\n",
        "#building neural network\n",
        "net=tflearn.input_data(shape=[None, len(train_x[0])])\n",
        "net=tflearn.fully_connected(net,10)\n",
        "net=tflearn.fully_connected(net,10)\n",
        "net=tflearn.fully_connected(net,len(train_y[0]), activation='softmax')\n",
        "net=tflearn.regression(net)\n",
        "\n",
        "#defining model and setting up tensorboard\n",
        "model=tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
        "\n",
        "#start training\n",
        "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "model.save('model.tflearn')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.00726\u001b[0m\u001b[0m | time: 0.008s\n",
            "| Adam | epoch: 1000 | loss: 0.00726 - acc: 1.0000 -- iter: 24/32\n",
            "Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.00731\u001b[0m\u001b[0m | time: 0.011s\n",
            "| Adam | epoch: 1000 | loss: 0.00731 - acc: 1.0000 -- iter: 32/32\n",
            "--\n",
            "INFO:tensorflow:/content/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LA_5QFbsUUc"
      },
      "source": [
        "import pickle\n",
        "pickle.dump({'word':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open(\"training_data\",\"wb\"))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl_Kv75avdJP"
      },
      "source": [
        "#restoring all the data structures\n",
        "data = pickle.load(open(\"training_data\",\"rb\"))\n",
        "\n",
        "words   =data['word']\n",
        "classes =data['classes']\n",
        "train_x =data['train_x']\n",
        "train_y =data['train_y']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue66f586wgQQ"
      },
      "source": [
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLVolYxww6rW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a489e0-59cb-48d3-f7fa-e3f24dcf2b41"
      },
      "source": [
        "#load the saved model\n",
        "model.load('./model.tflearn')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/model.tflearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeBXcDR5xBfM"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "  #tokenize the token\n",
        "  sentence_words=nltk.word_tokenize(sentence)\n",
        "  #stemming each word\n",
        "  sentence_words=[stemmer.stem(word.lower()) for word in sentence_words]\n",
        "  return sentence_words\n",
        "\n",
        "#return bag of word array:0 and 1 for each word in the bag that exists\n",
        "def bow(sentence, words, show_details=False):\n",
        "  #tokenize sentence\n",
        "  sentence_words=clean_up_sentence(sentence)\n",
        "  #generating bag of words\n",
        "  bag=[0] * len(words)\n",
        "  for s in sentence_words:\n",
        "    for i,w in enumerate(words):\n",
        "      if w ==s:\n",
        "        bag[i] = 1\n",
        "        \n",
        "        if show_details:\n",
        "          print(\"found in bag: %s\" % w)\n",
        "  return (np.array(bag))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDnZoojwyXI9"
      },
      "source": [
        "ERROR_THRESHOLD = 0.0\n",
        "def classify(sentence):\n",
        "  #generate probabilities from the model\n",
        "  results = model.predict([bow(sentence, words)])[0]\n",
        "  \n",
        "  #filter out prediction below a threshold\n",
        "  results = [[i,r] for i, r in enumerate(results) if r> ERROR_THRESHOLD]\n",
        "  \n",
        "  #sort by strength of probability\n",
        "  results.sort(key=lambda x: x[1], reverse=True)\n",
        "  return_list=[]\n",
        "  \n",
        "  for r in results:\n",
        "    return_list.append((classes[r[0]], r[1]))\n",
        "  \n",
        "  #return tuple of intent and probability\n",
        "  return return_list\n",
        "\n",
        "def response(sentence, userID='123', show_details=False):\n",
        "  results=classify(sentence)\n",
        "  \n",
        "  if results:\n",
        "    while results:\n",
        "      for i in intents['intents']:\n",
        "        if i['tag'] == results[0][0]:\n",
        "          return print(random.choice(i['responses']))\n",
        "      results.pop(0)\n",
        "  "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwmpKMu90gXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6bac7ab-d688-4905-c128-67f9b31182a9"
      },
      "source": [
        "classify('how old are you?')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 0.99053675),\n",
              " ('greeting', 0.006074506),\n",
              " ('help', 0.0032399264),\n",
              " ('name', 0.00011791937),\n",
              " ('goodbye', 3.0966672e-05)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sY_y3G81NoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a537d6f8-274f-4044-8248-6c7a4e4b6c35"
      },
      "source": [
        "response('how old are you?')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am old and wise\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6faVi3l1l9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648fe0af-66e2-4a72-8e2c-a80bb6cc08ac"
      },
      "source": [
        "response('Bye')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sad to see you go :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ByRPlyX2VrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3689daa-de6b-4121-bebe-a5bfc085bae2"
      },
      "source": [
        "response('good day')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_JBIxVB5-9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752aa1f5-e847-4891-8753-5bb59638ddda"
      },
      "source": [
        "response('what is your name?')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm Reemz.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFf7asDX6DG5",
        "outputId": "35e49fbc-6884-4cfa-a347-341c8ea48251"
      },
      "source": [
        "msg=''        \n",
        "### MAIN PROGRAM ###\n",
        "print(\"\\n Hey ! I'm a Chatbot !\\n Start a Conversation with me ! :D\\n\\n\\n\")\n",
        "\n",
        "while classify(msg)[0][0] != 'goodbye':    \n",
        "    # get the user input\n",
        "    msg = input(\"You: \")\n",
        "    print(\"Bot:\",end=' ')\n",
        "    response(msg)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Hey ! I'm a Chatbot !\n",
            " Start a Conversation with me ! :D\n",
            "\n",
            "\n",
            "\n",
            "You: hi\n",
            "Bot: Hi there, how can I help?\n",
            "You: how old are you?\n",
            "Bot: I am old and wise\n",
            "You: what is your name?\n",
            "Bot: You can call me Reemz.\n",
            "You: what do you do?\n",
            "Bot: I can help you with whatever you tell me to.\n",
            "You: bye \n",
            "Bot: Sad to see you go :(\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}